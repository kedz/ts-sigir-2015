\section{Motivation}

%KM If we are short on space, not sure how much this section is needed as it's
%somewhat repetitive of intro.

%KM - Chris, could you get some good references to work in the crisis
%informatics space.
Crisis informatics\cite{?} is dedicated to finding methods for sharing the
right information in a timely fashion with relief organizations during a major crisis. With the
increasing impact of climate change, the world is seeing an increase in
disasters such as hurricanes, tornadoes, flooding and typhoons, all of which
cause major damage and wreak havoc with food supplies, housing, and health
issues. Health epidemics, such as the ebola crisis in West Africa, also create
a need for timely information about where problems are greatest. Social and
political 
crises, such as the current situation in Syria, create similar needs for
humanitarian assistance.

At times of crisis, however, social media can overwhelm current information
systems with the quantity of information, much of which is irrelevant,
unnecessary detail, or out of date. Many approaches have focused on
human-in-the-loop approaches \cite{?} to enable people on the ground to update
crisis interfaces with information about needs. Others have ..
%KM - Chris - fill this out a bit.





%KM - PRobably should make a little more inclusive, there are graph based
%models that use methods such lexical similarity to build the graph,
%probabilistic methods (e.g., based on word probabilities, regression or
%topical signatures). There are also methods that use topic segmentation or
%modeling and select sentences for each topic.



Multi-document summarization offers potential for enabling automatic updates of
relevant, salient information at regular intervals. It would provide
information even when human volunteers are unable to and would filter out
unnecessary and irrelevant detail. 
Most generic multi-document summarization approaches involve either sentence 
clustering or ranking sentences according to metrics that measure the salience
of their words. 
When the summarization task
is broad or underspecified,
%clustering is most appropriate in that the data
these methods are appropriate as they let the data
``to speak for itself.''
%This is probably most true when summarization is 
%interpreted to mean exploratory data analysis. 
When there are more constraints on the output, as in query-focused
summarization or the crisis update task we present here,
results are more accurate when
%often easier to design
appropriate features for the ranking approach are used (e.g., amount of word
overlap for the query-focused approach).
%either by rule or learning-to-rank.
The primary contribution of this paper
is a framework for combining both of these approaches using affinity
propagation clustering as well as disaster-specific features.

\begin{figure}
\begin{tabular}{| p{8cm} |}
\hline
\textbf{Event: Hurricane Sandy}\\
\includesvg[width=\columnwidth]{docfreq}\\
\textbf{Example Nuggets:}\\
$\cdot$ October 22nd Sandy strengthened from a tropical depression into a tropical storm\\
$\cdot$ could turn towards Bermuda or go straight to the Eastern U.S.\\
$\cdot$ 11 pm Oct 24 winds 50 mph\\
%$\cdot$ 11 pm Oct 24 moving NNE at 9 knots\\
$\cdot$ More than 1,000 people went to shelters in Jamaica\\
\hline
\end{tabular}
\end{figure}


\ckcomment{Not sure how to present this together, we also essentially evaluate
a salience model by feature ablation for the TS task, but this feels very specific compared to the general framework idea.}

\fdcomment{I guess I think we need to two things in this section (and/or introduction).  1. explain why the problem matters.  2. explain why our approach is compelling.  }

\fdcomment{if easy to generate, would be good to have a single figure for an event that includes 1. the query, 2. the distribution of (filtered) document volume over time, and 3. a sample of the gold nuggets.  this provides the reader with a visual explanation of the problem, the solution, and the difficulty}
