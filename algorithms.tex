\section{Algorithm}
\label{sec:background}
\input{algorithm/introduction.tex}
\input{algorithm/filtering.tex}
\input{algorithm/salience.tex}
\input{algorithm/ap.tex}
\input{algorithm/novelty.tex}






%Each element $R(i,k)$ expresses the fitness of the $k^{th}$ point to serve as
%the exemplar of the $i^{th}$ point relative to other potential exemplars.
%Each element $A(i, k)$ represents the $k^{th}$ point's ``availability'' to
%serve as an exemplar of the $i^{th}$ point, taking into account other points'
%preference for the $k^{th}$ point as an exemplar.



%While, AP does not set the number of exemplars before-hand, a lower overall
%preference values will result in a smaller number of exemplars.


%arbitrary pair-wise similarity function $S: \mathcal{R}^d \rightarrow
%\mathcal{R}$, where $d$ is the dimension of the data being clustered and a
%real-valued preference $\pi_i$ quantifying our belief a priori of the
%$i^{th}$ element's ability to serve as an exemplar.






%the formation of sentence clusters around more salient sentences. We
%introduce the affinity propagation algorithm as as an elegant way to
%incorporate our salience predictions into a

%What follows is a description of our ongoing event summarization efforts.  We
%briefly situate our approach to summarization within the broader field of
%multi-document summarization, and then introduce the affinity propagation
%algorithm which we use for clustering. This algorithm allows us to elegantly
%address the salient sentence selection problem by incorporating our prior
%beliefs about sentence quality. Next, we describe out method for modeling
%summary sentence quality, and the features used in this model.  Finally, we
%address future features and system improvements that we are incorporating
%into our summarizer.


%
% \subsection{Temporal Summarization System}
% \label{sec:approach}
%
%
% We first begin with some notation. For a given event, let $\corpus$ be the set
% of retrieved documents. A document $\doc \in \corpus$ is an ordered sequence
% of sentences $\{\sent_{1,\doc},\ldots,\sent_{|\doc|,\doc} \}$.
% Additionally, each document has a timestamp $\dtime(\doc)$. Finally, let
% $\corpus_{\hour_i}$ be the set of retrieved documents such that
% $\hour_i \le \dtime(\doc) < \hour_{i+1}$ for all $\doc \in \corpus_{\hour_i}$.
%
% %Our TS system involves ? phases involving sentence level classification,
% %regression, and clustering.
% Figure ? outlines our general temporal summarization algorithm. The description
% of our approach is as follows.
% For each event, we iterate over the retrieved
% documents in hourly chunks, emitting 0 or more updates at each hour.
% At each hour $\hour$, we process each document
% $\doc \in \corpus_{\hour}$. First, we identify where the document content
% actually is; Second, we predict the salience of all content sentences.
% To account for redundancy, the predicted salience is penalized based on the
% distance of the sentence in question to the previous summary updates.
%
% Finally, we cluster all content sentences
% for the current hour using the penalized salience predictions to bias the
% formation
% of clusters around the most salient sentences. For each cluster center, or
% exemplar, that results, we check that the salience is above a threshold and
% that it does not belong to a singleton cluster; exemplars that satisfy these
% conditions are emitted as an update.
% Additionally, we maintain the complete set of updates in order to penalize
% salience predictions in the subsequent time steps.
%
% % \begin{figure}
% % \centering
% \begin{algorithm}%[H]
%  \KwData{$Query$ --- the set of event query words\\
%         $SC$ --- the stream corpus\\
%
%
% }
%  ~\\
%  Initialize empty list $\mathbf{U}$ of updates\\
%  Initialize empty list $\boldsymbol{\Pref}^{(U)}$ of update preferences\\
%  $\corpus \gets $ RetrieveDocuments($Query$, $SC$) (See \cref{subsec:Document Retrieval})\\
%  \For{$i \gets 1,\ldots,t $}{
%
%   Initialize empty lists $\SMat, \Pref$ \;
%
%
%   \For{$\doc \in \corpus_{\hour_i}$}{
%    \For{$\sent \in \operatorname{getContent}(\doc, Query)$ (See \cref{subsec:Content Detection})\\}{
%      $\SMat.\operatorname{append}(\sent)$\;
%      $\sigma \gets \operatorname{PredictSalience}(\sent)$ (See \cref{subsec:Predict})\\
%      $\Pref.\operatorname{append}(\sigma)$\;
%
%    }
%   }
%   %$\Sim \gets \operatorname{ComputeSimilarityMatrix}(X)$\;
%   %$\operatorname{}$
%   ~\\
%   $\mathbf{U}_{h_i}, \Pref^{(U)}_{h_i} \gets \operatorname{SentenceSelection}
%     (\SMat, \Pref)$ (See \cref{subsec:SentenceSelection})\\
%   ~\\
%   $\operatorname{Emit}(\mathbf{U}_{h_i})$ \\
%   $\mathbf{U}\operatorname{.append}(\mathbf{U}_{h_i})$ \\
%   $\mathbf{\Pref}^{(U)}\operatorname{.append}(\Pref^{(U)}_{h_i})$ \\
% %gets \Updates_{cache} \cup \Updates_{\hour}$\;
%
%  }
%  \caption{Temporal Summarization Algorithm}
% \end{algorithm}
% % \end{figure}

% \subsubsection{Document Retrieval}\label{subsec:Document Retrieval}
%
% The focus of our system was on salience prediction and clustering stages, and
% so we relied heavily on the pre-filtered corpus provided by the track
% organizers. The TREC Temporal Summarization 2014 (TREC-TS-2014F) corpus is
% a subset of the full TREC 2014 StreamCorpus and is
% intended to be a high recall retrieval of documents related to all 15 of
% the 2014 TS events.
%
% Track participants were provided with a set of query words for each event.
% For example, the event ``Costa Concordia disaster and recovery'' had query
% words [``costa'', ``concordia''].
% In order to construct an event specific corpus,
% we retrieve all documents whose timestamps fall within the event start/stop
% times and whose raw html content contains at least one keyword from the
% event's query words. We further restricted our document set to only those
% articles from the news domain.




% \subsubsection{Sentence Selection}\label{subsec:SentenceSelection}


