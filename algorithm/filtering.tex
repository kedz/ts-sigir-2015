\subsection{Filtering Content}
\label{sec:filtering}
We simulate our system using realistic data insofar as the document stream consists of relevant and non-relevant content.  As with many information retrieval systems, we use a crude, first phase of high-recall content filtering for both documents and sentences.  

\subsubsection{Filtering Documents}
\label{sec:filtering:documents}
As a first filter, we retained only those documents whose raw html content contains at least one keyword from the event's query words. We further restricted our document set to only those articles from the news domain.\footnote{This filtered set was distributed by track organizers.} \fdcomment{not sure how much we have to describe this.}

\subsubsection{Filtering Sentences}
\label{sec:filtering:sentences}
Structural html artifacts and sentence tokenization errors can negatively effect the performance of a temporal summarization system. Examples of the former include strings of link text like ``World Politics Sports ...'', while examples of the latter included concatenations of unrelated content  (e.g. segmentation errors treating two headlines as a single sentence).  


In order to filter out these problematic inputs, we trained a classifier to identify which sentences came from inside a document's main article and which came from various headers, titles, menus, and links to other content. We collected random sentences and manually labeled whether the sentence came from inside or outside the document's main article. We then trained a logistic  regression classifier using: 
\begin{enumerate*}[label=\itshape\alph*\upshape)]
	\item the position of the sentence,
	\item word counts,
	\item the last token in the sentence,
	\item the last two tokens in the sentence, and
	\item the last three tokens in the sentence.
\end{enumerate*}
These features were sufficient to capture the main difference between content and non-content sentences, which  was that content sentences generally ended with sentence final punctuation, i.e. periods or a closing quotation mark. \fdcomment{include summary performance numbers here; also a reference to prior work.}

After identifying the subset of a document's sentences that are content sentences, we check to make sure \emph{all} event query terms can be found within the document's content sentences. If so, we send the content sentences on to the next stage of our pipeline; otherwise we ignore all sentences in this document.

