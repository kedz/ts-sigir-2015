\subsection{Selecting Sentences}
\label{sec:ap}
Because we are analyzing multiple text streams, there is likely to be a large amount of redundancy of content.  That is, when a sub-event occurs, several news providers will publish stories reporting the occurrence.  Predicting the salience of each sentence in isolation, as was described in the previous section, provides us with a measure of the usefulness of a sentence independent of other decisions.  In order to reduce the redundancy in our updates, we need to select sentences that  are both salient and novel.

We take a two phase approach to dealing with redundancy.  First, we select a set of the diverse, highly-salient sentences within our set of candidates from the current hour.  This ensures that we focus only on the most recent sub-events and, as a result, indirectly helps preserve low latency.  Second, we compare those exemplars to update decisions made in previous hours.  This ensures that we do not repeat sub-events previously output to the user.

\subsubsection{Selecting Exemplars within the Hour}
\fdcomment{subsection title needs to be changed}

Many existing multi-document summarization systems operate by clustering a set of previously-deemed salient sentences.  Because our salience assessments are based on a model, we cannot assume that values are perfectly reliable.  Therefore using a clustering technique that ignored the uncertainty in the salience prediction may have undesirable outcomes.  


To address the uncertain in salience predictions, we adopted an algorithm known as affinity propagation (AP) \cite{dueck2007non}.  AP is a message passing algorithm that identifies both exemplar data points and assignments of each point to an exemplar.  This is done iteratively by passing \emph{responsibility} and \emph{availability} messages between data points that quantify the fitness of one data point to represent another, and the fitness of a data point to be represented based on the choices of other data points respectively.

AP is parameterized by an $\numcandidates\times \numcandidates$ similarity matrix $\candidateSimMat$ and an $\numcandidates\times 1$ preference vector $\preferences$, derived from our salience predictions.  $\candidateSimMat$ is a real-valued matrix where $\candidateSimMatij{i}{j}$ is the \emph{semantic} similarity of the $i$-th data point to the $j$-th candidate sentence.  Note that this matrix, whose construction is described below, is different from our feature-based kernel matrix $\kernelMatrix$, in that it measures the similarity of the content as opposed to the properties of the content.   The vector $\pi$ is a real-valued vector where $\preferences$ expresses our preference that the $i$-th data point can serve as an exemplar a priori of other data points. 


AP has several useful properties that comport well with the temporal summarization problem. First, the number of clusters $k$ is not a hyper-parameter of the model. Since we will be running this algorithm every hour, the usual methods of hyperparameter search become infeasible.  This is especially critical in our situation, where the number of sub-events is likely to change dramatically between hours. The number of clusters falls out of the algorithm organically--lower overall preference values will result in fewer clusters. Secondly, the arbitrary nature of the preferences allow us to incorporate a variety of signals for identifying the best exemplars, i.e. salience and redundancy signals.  The preferences can be thought of as self-similarities (similarities that pairwise-comparison based algorithms would ignore) that we can exploit to  incorporate our prior beliefs about a data point.  Finally, cluster exemplars are guaranteed to be actual data points. Many  clustering algorithms group data around mathematical objects (e.g., the mean) that are not necessarily observed in the data. The extractive nature of this TS task requires that we emit actual data points (i.e. sentences). We are able to sidestep  the additional requirement of selecting a most representative cluster member, as this is computed explicitly in the AP  algorithm. 


\fdcomment{probably need more content explaining AP.}

% In the sentence selection stage, we use the salience predictions from our GP
% model as preferences in the AP clustering algorithm. The AP algorithm is
% parameterized by a similarity matrix $\mathbf{S}$ and a vector of
% preferences $\boldsymbol{\pi}$; we found AP to be very sensitive to these
% parameters, and did not perform robustly on our range of inputs.
% In order to improve the quality of the clusters and exemplar selection,
% we re-scaled both the raw inputs $\mathbf{S}$ and $\boldsymbol{\pi}$.
% The raw preferences are scaled to lie within the  range $(-3, -2)$
%
% The initial matrix $\mathbf{S}$ is computed by finding the pairwise semantic
% similarity between input sentences. Self-similarities and similarities below
% a threshold $\lambda$ were masked and the remaining values scaled to the range
% $(-3, -1)$.

% \subsubsubsection{Semantic Similarity}
% \label{subsec:semsim}
The AP algorithm requires two data structures: the semantic similarity matrix $\candidateSimMat$ and the preference vector $\preferences$.  In order to construct $\candidateSimMat$, we use the weighted textual matrix factorization (WTMF) model of \cite{guo2012simple}. This  model can be thought of as a variant of latent semantic analysis \cite{deerwester:lsa},  where strings, sentences in our case, are projected into a lower dimensional space.  We then use the cosine similarity of embedded vectors in this space to define entries in $\candidateSimMat$.  The preference vector $\preferences$ is constructed by using salience scores rescaled to lie within the  range $(-3, -2)$.  \fdcomment{not sure how much we have to justify this.}




% More formally, we have a term-sentence matrix
% $\mathbf{X}\in\mathcal{R}^{v \times n}$ representing $n$ sentences with a
% vocabulary of $v$ words; $\mathbf{X}_{i,j}$ indicates is non-zero if sentence
% $j$ contains word $i$. In the WTMF regime, we want to find an approximation
% of $\mathbf{X} \approx \mathbf{P}^T\mathbf{Q}$, where
% $\mathbf{P} \in \mathcal{R}^{k \times v}$ is a latent word vector space and
% $\mathbf{Q} \in \mathcal{R}^{k \times n}$ is a latent sentence vector
% space. These matrices are found by minimizing the objective function
%
% $$\sum_i^v \sum_j^n \mathbf{W}_{i,j}(\mathbf{P}_{\cdot,i}^T
% \mathbf{Q}_{\cdot,j}
% - \mathbf{X}_{i,j})^2
%  + \lambda ||\mathbf{P}||_2^2 + \lambda ||\mathbf{Q}||_2^2$$
%
% where $\mathbf{W}_{i,j} =
% \begin{cases} 1, & \textrm{if $\mathbf{X}_{i,j} \ne 0$ } \\
% w_m, & \textrm{if $\mathbf{X}_{i,j} = 0$ }\\
% \end{cases}$
% and $\lambda$ is a hyperparameter controlling the regularization terms.
%
% The $w_m$ term is another model hyperparameter that is set to a small constant
% ($\le .01$). The weight matrix $\mathbf{W}$ has the effect of discounting the
% reconstruction error of missing terms (words that did not occur a sentence).
%
% Given an unseen sentence $\hat{i}$ we can project its term vector into the
% latent sentence vector space with
%
% $$
% \mathbf{Q}_{\cdot,\hat{i}} = (\mathbf{P}\mathbf{\tilde{W}}^{(\hat{i})}
% \mathbf{P}^T  + \lambda\mathbf{I} )^{-1}
% \mathbf{P}\mathbf{\tilde{W}}^{(\hat{i})} \mathbf{X}_{\cdot, \hat{i}}
% $$
%
% where $\mathbf{\tilde{W}}^{(\hat{i})}$ is an $v\times v$ diagonal matrix
% where $\mathbf{\tilde{W}}^{(\hat{i})}_{j,j}$ is equal to $1$ or $w_m$
% depending on whether or not the $j$-th term occurs in sentence $\hat{i}$.
%
%
% The WTMF model is used extensively throughout our TS system. When making any
% pairwise comparison between sentence $i$ and $j$, we first construct
% their latent sentence vectors $\mathbf{Q}_{\cdot,i}$ and
% $\mathbf{Q}_{\cdot,j}$ and then find the cosine similarity
% $\displaystyle \operatorname{cos-sim}
% (\mathbf{Q}_{\cdot,i}, \mathbf{Q}_{\cdot,j}) =
% \frac{\mathbf{Q}_{\cdot,i}^T\mathbf{Q}_{\cdot,j}}{||\mathbf{Q}_{\cdot,i}||_2
% ||\mathbf{Q}_{\cdot,j}||_2   }$.
%
%
% Because the events for the TS task come from different domains, we construct
% domain specific latent word vector spaces for each domain using in-domain
% Wikipedia pages (see~\cref{sec:data} for more details).

%
% \subsubsection{Preferences}
% The second data structure we need for AP is the preference vector $\preferences$.
% Before rescaling, we first penalize each $\boldsymbol{\pi}_i$ based on
% the aggregate similarity of input sentence $\mathbf{s}_i$ to the set of previous updates
% $\mathbf{U}$. We call this the redundancy penalty
%
% $$\rho_i = \sum_j \frac{\boldsymbol{\pi}^{(U)}_{j}\operatorname{cos-sim}(\mathbf{s}_i, \mathbf{U}_j)}
% {\sum_{j^\prime}\operatorname{cos-sim}(\mathbf{s}_i, \mathbf{U}_{j^\prime})} $$
% where $\boldsymbol{\pi}^{(U)}_{j}$ is the salience prediction of the $j$
% previous update. We calculate our new penalized preferences
% $\boldsymbol{\pi}^{(\rho)}$ where $\boldsymbol{\pi}^{(\rho)}_i = \boldsymbol{\pi}_i - \rho_i$.
% Finally, we rescale $\boldsymbol{\pi}^{(\rho)}$ such that all values lie
% within the range $(-3,-2)$.
%
