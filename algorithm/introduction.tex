
We first begin with some notation. For a given event, let $\corpus$ be the set
of retrieved documents. A document $\doc \in \corpus$ is an ordered sequence
of sentences $\{\sent_{1,\doc},\ldots,\sent_{|\doc|,\doc} \}$. 
Additionally, each document has a timestamp $\dtime(\doc)$. Finally, let 
$\corpus_{\hour_i}$ be the set of retrieved documents such that 
$\hour_i \le \dtime(\doc) < \hour_{i+1}$ for all $\doc \in \corpus_{\hour_i}$.

%Our TS system involves ? phases involving sentence level classification, 
%regression, and clustering. 
Figure ? outlines our general temporal summarization algorithm. The description
of our approach is as follows.
For each event, we iterate over the retrieved 
documents in hourly chunks, emitting 0 or more updates at each hour.
At each hour $\hour$, we process each document
$\doc \in \corpus_{\hour}$. First, we identify where the document content
actually is; Second, we predict the salience of all content sentences.
To account for redundancy, the predicted salience is penalized based on the 
distance of the sentence in question to the previous summary updates.

Finally, we cluster all content sentences 
for the current hour using the penalized salience predictions to bias the 
formation
of clusters around the most salient sentences. For each cluster center, or 
exemplar, that results, we check that the salience is above a threshold and 
that it does not belong to a singleton cluster; exemplars that satisfy these
conditions are emitted as an update.
Additionally, we maintain the complete set of updates in order to penalize
salience predictions in the subsequent time steps. 

% \begin{figure}
% \centering 
\begin{algorithm}%[H]
 \KwData{$Query$ --- the set of event query words\\ 
        $SC$ --- the stream corpus\\

         
}
 ~\\
 Initialize empty list $\mathbf{U}$ of updates\\
 Initialize empty list $\boldsymbol{\Pref}^{(U)}$ of update preferences\\
 $\corpus \gets \operatorname{FilterDocuments}(Query, SC)$ (See \cref{sec:filtering:documents})\\
 \For{$i \gets 1,\ldots,t $}{

  Initialize empty lists $\SMat, \Pref$ \;
      

  \For{$\doc \in \corpus_{\hour_i}$}{
   \For{$\sent \in \operatorname{FilterSentences}(\doc, Query)$ (See \cref{sec:filtering:sentences})\\}{
     $\SMat.\operatorname{append}(\sent)$\;
     $\sigma \gets \operatorname{PredictSalience}(\sent)$ (See \cref{subsec:Predict})\\     
     $\Pref.\operatorname{append}(\sigma)$\;
     
   }        
  }
  %$\Sim \gets \operatorname{ComputeSimilarityMatrix}(X)$\;
  %$\operatorname{}$
  ~\\ 
  $\mathbf{U}_{h_i}, \Pref^{(U)}_{h_i} \gets \operatorname{SentenceSelection}
    (\SMat, \Pref)$ (See \cref{sec:ap})\\
  ~\\
  $\operatorname{Emit}(\mathbf{U}_{h_i})$ \\ 
  $\mathbf{U}\operatorname{.append}(\mathbf{U}_{h_i})$ \\
  $\mathbf{\Pref}^{(U)}\operatorname{.append}(\Pref^{(U)}_{h_i})$ \\
%gets \Updates_{cache} \cup \Updates_{\hour}$\;

 } 
 \caption{Temporal Summarization Algorithm}
\end{algorithm}
% \end{figure}
